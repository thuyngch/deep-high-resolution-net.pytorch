{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os, json, cv2\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from matplotlib import pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from FOTS.model.keys import keys\n",
    "from FOTS.data_loader.data_loaders import SynthTextDataLoaderFactory\n",
    "from FOTS.utils.util import get_center_bbox, get_center_bboxes, draw_texts, strLabelConverter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = json.load(open(\"../debug.json\"))\n",
    "data_loader = SynthTextDataLoaderFactory(config)\n",
    "train_loader = data_loader.train()\n",
    "labelConverter = strLabelConverter(keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize detection information\n",
    "\n",
    "for data_idx, data in enumerate(train_loader):\n",
    "\n",
    "    image_files, images, score_maps, geo_maps, training_masks, transcripts, rectangles, mappings = data\n",
    "\n",
    "    plt.figure(figsize=(30,5*len(images)))\n",
    "    print(\"images\", images.shape)\n",
    "    print(\"score_maps\", score_maps.shape)\n",
    "    print(\"geo_maps\", geo_maps.shape)\n",
    "    print(\"training_masks\", training_masks.shape)\n",
    "    print(\"transcripts\", len(transcripts))\n",
    "    print(\"rectangles\", rectangles.shape)\n",
    "    print(\"mappings\", mappings.shape)\n",
    "    print(\"transcripts\", transcripts)\n",
    "    print(\"mappings\", mappings)\n",
    "\n",
    "    for image_idx, (image_file, image, score_map, geo_map, training_mask) in enumerate(zip(image_files, images, score_maps, geo_maps, training_masks)):\n",
    "        # print(image.shape, score_map.shape, geo_map.shape, training_mask.shape)\n",
    "\n",
    "        # Get image\n",
    "        image = image.numpy().transpose((1,2,0))\n",
    "        image = (image * np.array([0.229, 0.224, 0.225])[None,None,:] + np.array([0.485, 0.456, 0.406])[None,None,:])\n",
    "        image = (255*image).astype(np.uint8)\n",
    "        h, w = image.shape[:2]\n",
    "\n",
    "        # Get score_map\n",
    "        score_map = score_map.numpy().astype(np.uint8)[0]\n",
    "        score_map = cv2.resize(score_map, (w,h))\n",
    "        # print('score_map', score_map.min(), score_map.max())\n",
    "\n",
    "        # Get geo_map\n",
    "        geo_map = geo_map.numpy().transpose((1,2,0))\n",
    "        geo_map = cv2.resize(geo_map, (w,h))\n",
    "        # print('geo_map', geo_map.min(), geo_map.max())\n",
    "\n",
    "        # Get training_mask\n",
    "        training_mask = training_mask.numpy().astype(np.uint8)[0]\n",
    "        training_mask = cv2.resize(training_mask, (w,h))\n",
    "\n",
    "        # Visualize\n",
    "        plt.subplot(len(images), 8, 8*image_idx+1)\n",
    "        plt.imshow(image); plt.title(os.path.basename(image_file)); plt.axis('off')\n",
    "\n",
    "        plt.subplot(len(images), 8, 8*image_idx+2)\n",
    "        plt.imshow(image); plt.imshow(score_map, alpha=0.5, vmin=0, vmax=1); plt.title(\"score_map\"); plt.axis('off')\n",
    "        \n",
    "        plt.subplot(len(images), 8, 8*image_idx+3)\n",
    "        plt.imshow(image); plt.imshow(training_mask, alpha=0.5, vmin=0, vmax=1); plt.title(\"training_mask\"); plt.axis('off')\n",
    "        \n",
    "        plt.subplot(len(images), 8, 8*image_idx+4)\n",
    "        plt.imshow(image); plt.imshow(geo_map[...,0], alpha=0.5, vmin=0, vmax=geo_map[...,0].max()); plt.title(\"geo_map1\"); plt.axis('off')\n",
    "        \n",
    "        plt.subplot(len(images), 8, 8*image_idx+5)\n",
    "        plt.imshow(image); plt.imshow(geo_map[...,1], alpha=0.5, vmin=0, vmax=geo_map[...,1].max()); plt.title(\"geo_map2\"); plt.axis('off')\n",
    "        \n",
    "        plt.subplot(len(images), 8, 8*image_idx+6)\n",
    "        plt.imshow(image); plt.imshow(geo_map[...,2], alpha=0.5, vmin=0, vmax=geo_map[...,2].max()); plt.title(\"geo_map3\"); plt.axis('off')\n",
    "        \n",
    "        plt.subplot(len(images), 8, 8*image_idx+7)\n",
    "        plt.imshow(image); plt.imshow(geo_map[...,3], alpha=0.5, vmin=0, vmax=geo_map[...,3].max()); plt.title(\"geo_map4\"); plt.axis('off')\n",
    "        \n",
    "        plt.subplot(len(images), 8, 8*image_idx+8)\n",
    "        plt.imshow(image); plt.imshow(geo_map[...,4], alpha=0.5, vmin=0.0, vmax=3.14/2); plt.title(\"geo_map5\"); plt.axis('off')\n",
    "\n",
    "    # Break and show\n",
    "    if data_idx==0:\n",
    "        break\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize recognition information\n",
    "\n",
    "for data_idx, data in enumerate(train_loader):\n",
    "\n",
    "    image_files, images, score_maps, geo_maps, training_masks, transcripts, rectangles, mappings = data\n",
    "\n",
    "    plt.figure(figsize=(20,10*len(images)))\n",
    "    print(\"images\", images.shape)\n",
    "    print(\"score_maps\", score_maps.shape)\n",
    "    print(\"geo_maps\", geo_maps.shape)\n",
    "    print(\"training_masks\", training_masks.shape)\n",
    "    print(\"transcripts\", len(transcripts))\n",
    "    print(\"rectangles\", rectangles.shape)\n",
    "    print(\"mappings\", mappings.shape)\n",
    "    print(\"transcripts\", transcripts)\n",
    "    print(\"mappings\", mappings)\n",
    "\n",
    "    for image_idx, (image_file, image, score_map, geo_map, training_mask) in enumerate(zip(image_files, images, score_maps, geo_maps, training_masks)):\n",
    "\n",
    "        # Get image\n",
    "        image = image.numpy().transpose((1,2,0))\n",
    "        image = (image * np.array([0.229, 0.224, 0.225])[None,None,:] + np.array([0.485, 0.456, 0.406])[None,None,:])\n",
    "        image = (255*image).astype(np.uint8)\n",
    "        h, w = image.shape[:2]\n",
    "\n",
    "        # Get transcript\n",
    "        bbox_indicator = (mappings==image_idx)\n",
    "        transcript = transcripts[bbox_indicator]\n",
    "        rectangle = rectangles[bbox_indicator]\n",
    "        xc, yc = get_center_bboxes(rectangle)\n",
    "        image_text = draw_texts(image, transcript, xc, yc, fontsize=3, color=(255,255,0), thickness=3)\n",
    "\n",
    "        # Visualize\n",
    "        plt.subplot(len(images), 2, 2*image_idx+1)\n",
    "        plt.imshow(image); plt.title(os.path.basename(image_file)); plt.axis('off')\n",
    "\n",
    "        plt.subplot(len(images), 2, 2*image_idx+2)\n",
    "        plt.imshow(image_text); plt.title(\"OCR\"); plt.axis('off')\n",
    "\n",
    "    # Break and show\n",
    "    if data_idx==0:\n",
    "        break\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fots",
   "language": "python",
   "name": "fots"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
